{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from imageio import imsave\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from abcmodel.libs.cvat import JOINT_LABELS\n",
    "from higher_hrnet.libs.utils import read_tarfile\n",
    "from higher_hrnet.libs.predictor import Refine\n",
    "from higher_hrnet.models.higher_hrnet import HigherHRNet\n",
    "from higher_hrnet.libs.transforms import InferenceTransform\n",
    "from higher_hrnet.libs.clustering import SpatialClustering\n",
    "# #torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Higher HRNet(for pig instance segmentation/keypoint estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_key_model = TRTModule()\n",
    "#seg_key_model.load_state_dict(torch.load('../../seg_key_model_trt_v0.0.2.pth'))\n",
    "#seg_key_model = Refine(seg_key_model,\n",
    "#                       joint_labels=JOINT_LABELS,\n",
    "#                       average_tag=True)\n",
    "\n",
    "seg_key_model = HigherHRNet(num_keypoints=13,\n",
    "                            num_seg_classes=2,\n",
    "                            dim_tag=5).eval()\n",
    "seg_key_model.load_state_dict(torch.load(\n",
    "    os.path.join('/workspace', 'pig', 'model', 'seg_key_model.pth')))\n",
    "seg_key_model = seg_key_model.cuda().eval()\n",
    "seg_key_model = Refine(seg_key_model, JOINT_LABELS, average_tag=True)\n",
    "\n",
    "inference_transform = InferenceTransform(input_size=480)\n",
    "clustering = SpatialClustering(threshold=0.05, min_pixels=20, margin=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    x, t_inv = inference_transform(img)\n",
    "    x = x.unsqueeze(0).cuda()\n",
    "    \n",
    "    seg_pred, hm_preds, tag_preds = seg_key_model(x)\n",
    "    hr_hm = hm_preds[1].cpu()\n",
    "    seed = torch.sigmoid(tag_preds[0, -1]).cpu()\n",
    "    instance_map = clustering(tag_preds)\n",
    "    instance_map = instance_map.cpu().squeeze()\n",
    "    \n",
    "    ins_map = instance_map.numpy()\n",
    "    ins_map = cv2.resize(ins_map, (640,480), interpolation = cv2.INTER_NEAREST)\n",
    "    seg = seg_pred.softmax(dim=1)[0,1].cpu().numpy()\n",
    "    hms = hm_preds[1][0].cpu().numpy()\n",
    "    \n",
    "    return ins_map, seg, hms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/workspace/pig/data/'\n",
    "data_dir = os.path.join(DIR, 'tar')\n",
    "save_dir = os.path.join(DIR, 'images_20211125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_id = 20211125\n",
    "sorted(os.listdir(data_dir + '/%s'%date_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_id = '18-21-R8'\n",
    "os.makedirs(save_dir + '/%s/%s'%(date_id, room_id), exist_ok=True)\n",
    "\n",
    "file_list = sorted(glob(data_dir + '/%s/%s/*'%(date_id, room_id)))\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data and inference result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the pig with the ID in his body "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "file_path = file_list[idx]\n",
    "\n",
    "fp = file_path.split('/')[-1]\n",
    "data_id = fp.split('Z')[0]\n",
    "rgb, depth = read_tarfile(file_path)\n",
    "depth = cv2.resize(depth, (640,480))\n",
    "\n",
    "fig, ((ax1, ax2)) = plt.subplots(ncols=2, figsize=(12,12))\n",
    "\n",
    "ax1.imshow(rgb)\n",
    "ax1.set_title('RGB')\n",
    "\n",
    "ax2.imshow(depth)\n",
    "ax2.set_title('Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_map, seg, hms = predict(rgb)\n",
    "\n",
    "hms = cv2.resize(hms.transpose(1,2,0), (640,480)).transpose(2,0,1)\n",
    "for i in np.unique(ins_map):\n",
    "    if i != 0:\n",
    "        mask = cv2.resize((ins_map==i).astype(np.uint8), (640,480))\n",
    "        y, x = np.where(mask==1)\n",
    "        xmin, ymin = np.min([x,y], axis=1)\n",
    "        xmax, ymax = np.max([x,y], axis=1)\n",
    "        \n",
    "        file_id = data_id+'_'+str(xmin)+'_'+str(ymin)+'_'+str(xmax)+'_'+str(ymax) + '.png'\n",
    "        \n",
    "        print(file_id, (xmax-xmin)*(ymax-ymin))\n",
    "        plt.imshow(rgb[ymin:ymax,xmin:xmax])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ins_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in file_list[int(idx):]:\n",
    "    fp = file_path.split('/')[-1]\n",
    "    data_id = fp.split('Z')[0]\n",
    "    print(fp)\n",
    "    \n",
    "    rgb, _ = read_tarfile(file_path)                \n",
    "    ins_map, seg, hms = predict(rgb)\n",
    "\n",
    "    hms = cv2.resize(hms.transpose(1,2,0), (640,480)).transpose(2,0,1)\n",
    "    for i in np.unique(ins_map):\n",
    "        if i != 0:\n",
    "            mask = cv2.resize((ins_map==i).astype(np.uint8), (640,480))\n",
    "            y, x = np.where(mask==1)\n",
    "            xmin, ymin = np.min([x,y], axis=1)\n",
    "            xmax, ymax = np.max([x,y], axis=1)\n",
    "\n",
    "            if (xmax-xmin)*(ymax-ymin)>10000:\n",
    "            \n",
    "                file_id = data_id+'_'+str(xmin)+'_'+str(ymin)+'_'+str(xmax)+'_'+str(ymax) + '.png'\n",
    "\n",
    "#                 imsave(save_dir + '/%s/%s/'%(date_id, room_id) + file_id, rgb[ymin:ymax,xmin:xmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
