{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from pycocotools import mask as pymask\n",
    "from imageio import imsave\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "from abcmodel.lib.datasets.cvat import JOINT_LABELS\n",
    "from higher_hrnet.models.higher_hrnet import HigherHRNet\n",
    "from higher_hrnet.lib.predictor import Refine\n",
    "from higher_hrnet.lib.transforms import InferenceTransform\n",
    "from higher_hrnet.lib.clustering import SpatialClustering\n",
    "from abcmodel.lib.utils import read_tarfile\n",
    "from abcmodel.lib.datasets.cvat import deproject_pixel_to_point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak(hms, thresh=0.1):\n",
    "    hms[hms<thresh] = 0\n",
    "    center = np.pad(hms, [[0,0],[2,2],[2,2]])\n",
    "    up = np.pad(hms, [[0,0],[0,4],[2,2]])\n",
    "    down = np.pad(hms, [[0,0],[4,0],[2,2]])\n",
    "    left = np.pad(hms, [[0,0],[2,2],[0,4]])\n",
    "    right = np.pad(hms, [[0,0],[2,2],[4,0]])\n",
    "\n",
    "    peak = (center>up)&(center>down)&(center>left)&(center>right)\n",
    "    peak = peak[:,2:-2,2:-2]\n",
    "    return peak*hms\n",
    "\n",
    "def iou(b1, b2):\n",
    "    xmin = max(b1[0], b2[0])\n",
    "    ymin = max(b1[1], b2[1])\n",
    "    xmax = min(b1[2], b2[2])\n",
    "    ymax = min(b1[3], b2[3])\n",
    "    area1 = (b1[2]-b1[0])*(b1[3]-b1[1])\n",
    "    area2 = (b2[2]-b2[0])*(b2[3]-b2[1])\n",
    "    inter = max((xmax-xmin),0)*max((ymax-ymin),0)\n",
    "    union = area1+area2-inter\n",
    "    return inter/union\n",
    "\n",
    "def calc_iou(bbox1, bbox2):\n",
    "    return [[iou(b1, b2) for b1 in bbox2] for b2 in bbox1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Higher HRNet(for pig instance segmentation/keypoint estimation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_key_model = HigherHRNet(num_keypoints=13,\n",
    "                            num_seg_classes=2,\n",
    "                            dim_tag=5).eval()\n",
    "seg_key_model.load_state_dict(torch.load(\n",
    "    os.path.join('/workspace', 'pig', 'model', 'seg_key_model.pth')))\n",
    "seg_key_model = seg_key_model.cuda().eval()\n",
    "seg_key_model = Refine(seg_key_model, JOINT_LABELS, average_tag=True)\n",
    "\n",
    "inference_transform = InferenceTransform(input_size=480)\n",
    "clustering = SpatialClustering(threshold=0.05, min_pixels=20, margin=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    x, t_inv = inference_transform(img)\n",
    "    x = x.unsqueeze(0).cuda()\n",
    "    \n",
    "    seg_pred, hm_preds, tag_preds = seg_key_model(x)\n",
    "    hr_hm = hm_preds[1].cpu()\n",
    "    seed = torch.sigmoid(tag_preds[0, -1]).cpu()\n",
    "    instance_map = clustering(tag_preds)\n",
    "    instance_map = instance_map.cpu().squeeze()\n",
    "\n",
    "    ins_map = instance_map.numpy()\n",
    "    ins_map = cv2.resize(ins_map, (640,480), interpolation = cv2.INTER_NEAREST)\n",
    "    seg = seg_pred.softmax(dim=1)[0,1].cpu().numpy()\n",
    "    hms = hm_preds[1][0].cpu().numpy()\n",
    "    \n",
    "    return ins_map, seg, hms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV(GT) and annotated Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = pd.read_csv(os.path.join('/workspace/pig/data/images_20211125/annotation/1125_data.csv'))\n",
    "weight_df.head()\n",
    "\n",
    "# file_list = sorted(glob('/workspace/pig/data/20211125_annotate/*/PID/*/*.png'))\n",
    "file_list = sorted(glob(os.path.join('/workspace/pig/data/images_20211125/annotation', '*', '*', '*.png')))\n",
    "print(len(file_list))\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    file_names = file.split('/')\n",
    "    pid = file_names[-2]\n",
    "    fname = file_names[-1]\n",
    "\n",
    "    prefix, date, xmin, ymin, xmax, ymax =  fname.split('_')\n",
    "    fid = prefix+'_'+date\n",
    "\n",
    "    rid = file_names[-3].split('-')[-1].replace('IDs', '')\n",
    "\n",
    "    date = datetime.strptime(date, '%Y%m%d%H%M%S')\n",
    "    date = date.strftime(\"%Y/%m/%d\")\n",
    "    \n",
    "    ymax = ymax.replace('.png', '')\n",
    "    \n",
    "    sub_df = weight_df.query(f'DAY==\"{date}\" & ROOM ==\"{rid}\" & ID == \"{pid}\"')\n",
    "\n",
    "    if len(sub_df)>0:\n",
    "        data_list.append([\n",
    "            date, pid, fid, \n",
    "            sub_df.ROOM.iloc[0], \n",
    "            None, \n",
    "            sub_df.GT.iloc[0], \n",
    "            int(xmin),\n",
    "            int(ymin), \n",
    "            int(xmax), \n",
    "            int(ymax), \n",
    "            fname\n",
    "        ])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data_list, columns=([\n",
    "        'date', 'pigID', 'fileID', 'roomID', 'camera', 'GT', \n",
    "        'xmin',  'ymin',  'xmax', 'ymax', 'img_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.GT, range=(80,120), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アノテーションとのマッチング確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fileID.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_list = sorted(glob('/workspace/pig/data/tar/*/*/*.tar.gz'))\n",
    "\n",
    "for fid in sorted(df.fileID.unique()[15:20]):\n",
    "    _df = df.query(f'fileID == \"{fid}\"')\n",
    "    file_path = tar_list[np.argmax([(fid in tf) for tf in tar_list])]\n",
    "\n",
    "    floor_depth = 2440\n",
    "\n",
    "    rgb, depth = read_tarfile(file_path)\n",
    "    depth = cv2.resize(depth, (640, 480))\n",
    "\n",
    "    ins_map, seg, hms = predict(rgb)\n",
    "    ins_map = cv2.resize(ins_map, (640, 480), interpolation=cv2.INTER_NEAREST).astype(np.uint8)\n",
    "    hms = cv2.resize(hms.transpose(1, 2, 0), (640, 480)).transpose(2,0,1)\n",
    "\n",
    "    bbox1 = [[row.xmin, row.ymin, row.xmax, row.ymax] for i, row in _df.iterrows()]\n",
    "    bbox2 = []\n",
    "    for i in np.unique(ins_map):\n",
    "        if i != 0:\n",
    "            y, x = np.where(ins_map==i)\n",
    "            xmin, ymin = np.min([x,y], axis=1)\n",
    "            xmax, ymax = np.max([x,y], axis=1)\n",
    "            bbox2.append([xmin,ymin,xmax,ymax])\n",
    "\n",
    "    y_list, x_list = np.where(np.array(calc_iou(bbox1, bbox2))==1)\n",
    "    for i1, i2 in zip(y_list, x_list):\n",
    "        mid = np.unique(ins_map)[i2+1]\n",
    "        mask = (ins_map==mid).astype(np.uint8)\n",
    "        rle_mask = pymask.encode(np.asfortranarray(mask))\n",
    "        x,y,w,h = map(int, pymask.toBbox(rle_mask))\n",
    "\n",
    "        cropped_rgb = rgb[y:y+h,x:x+w] * mask[y:y+h,x:x+w, np.newaxis]\n",
    "        cropped_depth = depth[y:y+h,x:x+w] * mask[y:y+h,x:x+w]\n",
    "        cropped_mask = mask[y:y+h,x:x+w]\n",
    "\n",
    "        height = np.where(cropped_depth != 0, floor_depth - cropped_depth.astype(int), 0)\n",
    "\n",
    "        d_mean = cropped_depth.mean()\n",
    "        tl = deproject_pixel_to_point(pixel=[x, y], depth=d_mean, distorted=True)\n",
    "        br = deproject_pixel_to_point(pixel=[x+w, y+h], depth=d_mean, distorted=True)\n",
    "\n",
    "        w, l, _ = np.abs(tl - br)\n",
    "        mm_squared = w * l * (mask.sum() / np.prod(mask.shape))\n",
    "\n",
    "        print(f'pigID={file_path.split(\"/\")[-2]}IDs/{_df.iloc[i1].pigID}/{_df.iloc[i1][\"img_path\"]}')\n",
    "        print(f'idx={i1}, {str(_df.iloc[i1].GT)}kg, w={int(w)}, l={int(l)}, mm_squared={int(mm_squared)}')\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(4, 4))\n",
    "        ax[0].imshow(cropped_rgb)\n",
    "        ax[1].imshow(cropped_mask)\n",
    "        ax[2].imshow(cropped_depth)\n",
    "        ax[0].axes.yaxis.set_visible(False)\n",
    "        ax[1].axes.yaxis.set_visible(False)\n",
    "        ax[2].axes.yaxis.set_visible(False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depthの高さあっているか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.hist(depth[ins_map==0], range=(2000,2500), bins=50)\n",
    "print('floor depth: ', a[1][np.argmax(a[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = []\n",
    "save_dir = '/workspace/pig/data/images_20211125/images'\n",
    "\n",
    "for fid in sorted(df.fileID.unique()):\n",
    "    _df = df.query('fileID == \"{}\"'.format(fid))\n",
    "    file_path = tar_list[np.argmax([(fid in tf) for tf in tar_list])]\n",
    "\n",
    "    rgb, depth = read_tarfile(file_path)\n",
    "    depth = cv2.resize(depth, (640,480))\n",
    "\n",
    "    rgb_path = 'rgb_'+fid + '.jpg'\n",
    "    depth_path = 'depth_'+fid + '.png'\n",
    "    cv2.imwrite(os.path.join(save_dir, rgb_path), rgb)\n",
    "    imageio.imsave(os.path.join(save_dir, depth_path), depth.astype(np.uint16))\n",
    "    \n",
    "    ins_map, seg, hms = predict(rgb)\n",
    "    ins_map = cv2.resize(ins_map, (640,480), interpolation=cv2.INTER_NEAREST).astype(np.uint8)\n",
    "    hms = cv2.resize(hms.transpose(1,2,0), (640,480)).transpose(2,0,1)\n",
    "\n",
    "    bbox1 = [[row.xmin, row.ymin, row.xmax, row.ymax] for i, row in _df.iterrows()]\n",
    "\n",
    "    bbox2 = []\n",
    "    for i in np.unique(ins_map):\n",
    "        if i != 0:\n",
    "            y, x = np.where(ins_map==i)\n",
    "            xmin, ymin = np.min([x,y], axis=1)\n",
    "            xmax, ymax = np.max([x,y], axis=1)\n",
    "            bbox2.append([xmin,ymin,xmax,ymax])\n",
    "        \n",
    "    y_list, x_list = np.where(np.array(calc_iou(bbox1, bbox2))==1)\n",
    "    \n",
    "    for i1, i2 in zip(y_list, x_list):\n",
    "        mid = np.unique(ins_map)[i2+1]\n",
    "        mask = (ins_map==mid).astype(np.uint8)\n",
    "        rle_mask = pymask.encode(np.asfortranarray(mask))\n",
    "        assert rle_mask is not None\n",
    "        x,y,w,h = map(int, pymask.toBbox(rle_mask))\n",
    "        bbox = [x,y,w,h]\n",
    "\n",
    "        #cropped_rgb = rgb[y:y+h,x:x+w] * mask[y:y+h,x:x+w, np.newaxis]\n",
    "        cropped_depth = depth[y:y+h,x:x+w] * mask[y:y+h,x:x+w]\n",
    "        cropped_mask = mask[y:y+h,x:x+w]\n",
    "        \n",
    "        hm_path = 'rgb_'+fid+str(x)+str(y)+str(w)+str(h)+'.npy'\n",
    "        np.save(os.path.join(save_dir, hm_path), hms[:,y:y+h,x:x+w])\n",
    "\n",
    "        height = np.where(cropped_depth != 0, floor_depth - cropped_depth.astype(int), 0)\n",
    "\n",
    "        d_mean = cropped_depth.mean()\n",
    "        tl = deproject_pixel_to_point(pixel=[x, y], depth=d_mean, distorted=True)\n",
    "        br = deproject_pixel_to_point(pixel=[x+w, y+h], depth=d_mean, distorted=True)\n",
    "\n",
    "        w, l, _ = np.abs(tl - br)\n",
    "        mm_squared = w * l * (mask.sum() / np.prod(mask.shape))\n",
    "\n",
    "        gt_df.append([\n",
    "            _df.iloc[i1].GT,\n",
    "            _df.iloc[i1].roomID,\n",
    "            'None',\n",
    "            np.sum(cropped_mask),\n",
    "            bbox,\n",
    "            floor_depth,\n",
    "            Polygon(mask),\n",
    "            mm_squared,\n",
    "            floor_depth,\n",
    "            np.nan,\n",
    "            d_mean,\n",
    "            height.mean(),\n",
    "            height.max(),\n",
    "            height.std(),\n",
    "            w,\n",
    "            l,\n",
    "            'new', 'rgb_'+_df.iloc[i1].fileID+'.jpg', _df.iloc[i1].pigID,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            str(_df.iloc[i1].pigID)+str(_df.iloc[i1].GT), hm_path\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.DataFrame(gt_df, columns=([\n",
    "    'weight', 'loc', 'posture', 'num_pixels', 'bbox', 'floor_depth', 'polygon', \n",
    "    'mm_squared','camera_height', 'id', 'd_mean', 'h_mean', 'h_max', 'h_std', \n",
    "    'w', 'l', 'subset', 'filename', 'UID', 'lying', 'sitting', 'standing', 'ID', 'heatmap_filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.to_pickle(os.path.join(save_dir, 'df_final.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = []\n",
    "save_dir = '/workspace/pig/data/images_20211125/images'\n",
    "\n",
    "for fid in sorted(df.fileID.unique()):\n",
    "    _df = df.query('fileID == \"{}\"'.format(fid))\n",
    "    file_path = tar_list[np.argmax([(fid in tf) for tf in tar_list])]\n",
    "\n",
    "    rgb, depth = read_tarfile(file_path)\n",
    "    depth = cv2.resize(depth, (640,480))\n",
    "\n",
    "    rgb_path = 'rgb_'+fid + '.jpg'\n",
    "    depth_path = 'depth_'+fid + '.png'\n",
    "#     cv2.imwrite(os.path.join(save_dir, rgb_path), rgb)\n",
    "#     imageio.imsave(os.path.join(save_dir, depth_path), depth.astype(np.uint16))\n",
    "    \n",
    "    ins_map, seg, hms = predict(rgb)\n",
    "    ins_map = cv2.resize(ins_map, (640,480), interpolation=cv2.INTER_NEAREST).astype(np.uint8)\n",
    "    hms = cv2.resize(hms.transpose(1,2,0), (640,480)).transpose(2,0,1)\n",
    "\n",
    "    bbox1 = [[row.xmin, row.ymin, row.xmax, row.ymax] for i, row in _df.iterrows()]\n",
    "\n",
    "    bbox2 = []\n",
    "    for i in np.unique(ins_map):\n",
    "        if i != 0:\n",
    "            y, x = np.where(ins_map==i)\n",
    "            xmin, ymin = np.min([x,y], axis=1)\n",
    "            xmax, ymax = np.max([x,y], axis=1)\n",
    "            bbox2.append([xmin,ymin,xmax,ymax])\n",
    "        \n",
    "    y_list, x_list = np.where(np.array(calc_iou(bbox1, bbox2))==1)\n",
    "    \n",
    "    for i1, i2 in zip(y_list, x_list):\n",
    "        mid = np.unique(ins_map)[i2+1]\n",
    "        mask = (ins_map==mid).astype(np.uint8)\n",
    "        rle_mask = pymask.encode(np.asfortranarray(mask))\n",
    "        assert rle_mask is not None\n",
    "        x,y,w,h = map(int, pymask.toBbox(rle_mask))\n",
    "        bbox = [x,y,w,h]\n",
    "\n",
    "        #cropped_rgb = rgb[y:y+h,x:x+w] * mask[y:y+h,x:x+w, np.newaxis]\n",
    "        cropped_depth = depth[y:y+h,x:x+w] * mask[y:y+h,x:x+w]\n",
    "        cropped_mask = mask[y:y+h,x:x+w]\n",
    "        \n",
    "        hm_path = 'rgb_'+fid+str(x)+str(y)+str(w)+str(h)+'.npy'\n",
    "#         np.save(os.path.join(save_dir, hm_path), hms[:,y:y+h,x:x+w])\n",
    "\n",
    "        height = np.where(cropped_depth != 0, floor_depth - cropped_depth.astype(int), 0)\n",
    "\n",
    "        d_mean = cropped_depth.mean()\n",
    "        tl = deproject_pixel_to_point(pixel=[x, y], depth=d_mean, distorted=True)\n",
    "        br = deproject_pixel_to_point(pixel=[x+w, y+h], depth=d_mean, distorted=True)\n",
    "\n",
    "        w, l, _ = np.abs(tl - br)\n",
    "        mm_squared = w * l * (mask.sum() / np.prod(mask.shape))\n",
    "\n",
    "        gt_df.append([\n",
    "            _df.iloc[i1].GT,\n",
    "            _df.iloc[i1].roomID,\n",
    "            'None',\n",
    "            np.sum(cropped_mask),\n",
    "            bbox,\n",
    "            floor_depth,\n",
    "            Polygon(mask),\n",
    "            mm_squared,\n",
    "            floor_depth,\n",
    "            np.nan,\n",
    "            d_mean,\n",
    "            height.mean(),\n",
    "            height.max(),\n",
    "            height.std(),\n",
    "            w,\n",
    "            l,\n",
    "            'new', 'rgb_'+_df.iloc[i1].fileID+'.jpg', _df.iloc[i1].pigID,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            np.nan,\n",
    "            str(_df.iloc[i1].pigID)+str(_df.iloc[i1].GT), hm_path\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
